---
title: "CA and MCA of NYCABS dataset"
author: "Katerina Dimitrova, Jose Romero, Sergi Munoz"
date: "March 18, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r,include=FALSE}
#setwd("C://Users/Sergi/Desktop/Sergi/ADEI") #Change 
setwd("D:/ADEI/ADEI.git/trunk") #Change

```

# Load Required Packages: to be increased over the course
```{r}
rm(list=ls())
requiredPackages <- c("effects","FactoMineR","car", "factoextra","RColorBrewer","ggplot2","missMDA","mvoutlier","dplyr","ggmap","ggthemes","knitr","MVA","corrplot")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

# Useful function and Data
#setwd("C://Users/Sergi/Desktop/Sergi/ADEI") #Change 
load("Taxi5000_raw_DataDefinitivev1.RData")
calcQ <- function(x) {
  s.x <- summary(x)
  iqr<-s.x[5]-s.x[2]
  list(souti=s.x[2]-3*iqr, mouti=s.x[2]-1.5*iqr, min=s.x[1], q1=s.x[2], q2=s.x[3],        q3=s.x[5], max=s.x[6], mouts=s.x[5]+1.5*iqr, souts=s.x[5]+3*iqr ) }
```

#Leveling 
For better understanding of the results we will name the levels of the factorial variables

```{r}
levels(df$f.fare_amount)
levels(df$f.passenger) <- c("onePassager","multiPassagers")
levels(df$f.pickup_longitude) <- c("p.Y1","p.Y2","p.Y3","p.Y4") #pickup->p., longtitude->Y
levels(df$f.pickup_latitude) <- c("p.X1","p.X2","p.X3","p.X4") #pickup->p., latitude->X
levels(df$f.distance) <- c("Dist1","Dist2", "Dist3", "Dist4")#distance 1-4, 1 shortest
levels(df$f.dropoff_longitude) <- c("d.Y1","d.Y2", "d.Y3", "d.Y4")
levels(df$f.dropoff_latitude) <- c("d.X1","d.X2", "d.X3", "d.X4")
levels(df$f.fare_amount) <- c("FAmount1","FAmount2", "FAmount3", "FAmount4")
levels(df$f.extra) <- c("smallExtra","highExtra")
levels(df$f.MTA_tax) <- c("smallMTA","highMTA")
levels(df$f.Improvement_surcharge) <- c("smallSurcharge","highSurcharge")
levels(df$f.tip_amount) <- c("smallTip","highTip")
levels(df$f.toll) <- c("smallToll","highToll")
levels(df$f.total) <- c("CheapestTrip","CheapTrip","MediumTrip","ExpensiveTrip")
levels(df$f.ttime) <- c("Time1","Time2", "Time3", "Time4")
levels(df$f.espeed) <- c("Speed1","Speed2", "Speed3","Speed4")
levels(df$f.outlierPCAd1) <- c("Normald1", "Outlierd1")
levels(df$f.outlierPCAd2) <- c("Normald2", "Outlierd2")
levels(df$f.outlierPCAd3) <- c("Normald3", "Outlierd3")
levels(df$f.outlierPCAd4) <- c("Normald4", "Outlierd4")
levels(df$f.outlierPCA) <- c("Normal", "Outlier")

```


# Correspondence Analysis: f.cost (discretization of Total_amount) vs f.hour and f.tt and period
In this section we will interprete two Correspondence Analysis executed on our discretizated target variable (f.total) with 2 different factors of our data: pick_up_period and f.espeed.

## Total_amount vs pick_up_period
We generate the contingency table for this two variables and execute the chisq test.

```{r}
tt<-table(df[,c("f.total","pick_up_period")])
tt
prop.table(tt,1)
prop.table(table(df$pick_up_period))

```
Before getting into the chisq test, taking a look to the contingency table we can actually say very little, because the categories of pick_up_period are not well balanced and so "afternoon" is always taking a higher number of individuals for each category.

For the previous reason, we look at their marginal tables to better extrapolate our first impressions.
The marginal table relative to f.total it is just a confirmation for what we already said (not very helpfull): we have an unbalanced distribution: most of the trips were made during the afternoon in every range of price contended.


```{r}
prop.table(tt,2)
prop.table(table(df$f.total))
```

Then, moving on to the second marginal table (now, relative to pick_up_period variable) things get more even.
we can appreciate that the cheapest trips take place, in a greater proportion, during the morning, as me can also say that during the night occur the most expensive trips. On the other hand, the medium price categories are more associated to the afternoon.   

```{r}
chisq.test(tt)
```

From the chi-square test we see that the p.value is less than 0.05 which meand that we can reject the Nul hypotesis thus the two factors are dependent. The df is 9 which means that the chi value of the threshold is 16,9 and we see that we have X-squared = 36,42 which is bigger than 16,9. => We can deffinetly reject the hypotesis. Factors are dependent and so we can affirm that the conclusions made above are statistically significant.


### CA plot interpretation
The plot visually represents all the information we could have interpreted from the tables:

- At night the trips tend to be more expensive. 
- In the afternoon we find middle prices 
- Cheap trips stay between valley and morning.


```{r}
res.ca<-CA(tt)
lines(res.ca$row$coord[,1],res.ca$row$coord[,2],lwd=2,col="blue")
summary(res.ca,dig=2)
fviz_ca_biplot(res.ca,repel=TRUE)+theme_bw()
```


### Eigenvalues and dominant axes analysis. How many axes we have to consider
The two first dimensions explain 99% of the variance, so there is no need of further exploration. (Actually, only the first dim has more than 94% of the variance). 
We can be confident that the patterns we see in the CA plot represent the patterns that we would see if we could peer into n-dimensional space.
```{r}
res.ca$eig
fviz_eig(res.ca)

```


### Individuals
For the next output we deduce that the more extreme individuals are actually the most contributive ones for the specific axe of their coordinates.

```{r}
res.ca$row$contrib[,1:2]
res.ca$row$coord[,1:2]

```

## Total_amount vs f.ttime
Now we will look at the contingency table for this two variables and execute the chisq test.

```{r}
tt<-table(df[,c("f.total","f.ttime")])
tt
prop.table(tt,1)
prop.table(table(df$f.ttime))
prop.table(tt,2)
prop.table(table(df$f.total))
chisq.test(tt)
```

We can appreciate a directionality between the increment of f.total and the f.ttime values. The diagonal of the contingency table has most of individuals contended and this is proved by the marginal tables too (no matter which one you look at). Lastly, they have a really good balanced distribution for each of their categories (almost equitative in each of them).

The chisq test numerically validates what we have already seen: these two variable are completetly dependent.

### CA plot interpretation
The plot shows a visual representation of the conclusion above: the longer the trips the more they cost.
```{r}
res.ca<-CA(tt)
lines(res.ca$row$coord[,1],res.ca$row$coord[,2],lwd=2,col="blue")
```

### Eigenvalues and dominant axes analysis. How many axes we have to consider
We need to consider the first 2 dimentions which together explains 90% of the data.

```{r}
res.ca$eig
fviz_eig(res.ca)
summary(res.ca)
res.ca$row$contrib[,1:2]
res.ca$row$coord[,1:2]
res.ca$row$cos2[,1:2]
#The 2st two eigenectors give us 90% of the variance so they are sufficient. 
res.ca$eig
sum(res.ca$eig[1:2,1])/sum(res.ca$eig[1:3,1])
sum(res.ca$eig[1:3,1])
res.ca$call$marge.col

fviz_eig(res.ca)
summary(res.ca,dig=2)
fviz_ca_biplot(res.ca,repel=TRUE)+theme_bw()

```


II.  Individuals point of view: Are they any individuals "too contributive"?Are there any groups?

III. Interpreting map of categories: average profile versus extreme profiles (rare categories)
IV. Interpreting the axes association to factor map.


# Multiple Correspondence Analysis

In order to compute MCA we gather all the categorical variables that we want to use as an active ones in vars_cat vector.
We are not taking all distributed nor factors in it because we want to avoid using some extremely unbalanced variables such as Store_and_fwd_flag.

As a suplementary we will use the targets itselfs and the factor of the total_amount too.

```{r}
names(df)
vars_cat <- names(df)[c(1,19,20,22,27,29:35,39,41,42,43)]
#add f.totalamount as quali.sup
res.mca<-MCA(df[,c(vars_cat,"Total_amount")],quali.sup=c(4,14),quanti.sup=17)
```

## Axes analysis
Below are shown the histograms of Eigen values and explained variances -in this order- as the numerical table for each dimension.
In order to get the number of dimensions which we will take into account from now on, we keep only the dimensions associated to eigenvalues greater than 1/(nbvar), which is until the 17th dimension and we got almost 80% of the variance explained. 

```{r}
fviz_eig(res.mca)
fviz_screeplot(res.mca, addlabels = TRUE, ylim = c(0, 45))
get_eig(res.mca)
length <-length(which(res.mca$eig[,1]>=(1/length(df[,c(vars_cat)]))));length 
res.mca$eig[1:length,1]
summary(res.mca, dig=2,nbelements=50, ncp=4)
```



## Individuals
We have 4866 observation so each individual should have 100/4866 ~ 0.02 contribution.So the expected avaradge contribution is 0.02*Dim1 + 0.02*Dim2 = 0.02*0.1+0.02*0.78 = 0.035.So as we see in the two plots there are some too contributive individuals.

Too contributive groups would be:
- Individuals with longest travel time, high total price, high fare amount and longest distance
- Individulas with shortest travel time, lowest Fare Amount and lowest total amount
- Individuals with a dispach trip type and the biggest pickup and dropoff longtitude
- Individuals with smallest pickup and droppoff longitude and latitude.
```{r}

fviz_contrib(res.mca, choice = "ind", axes = 1:2, top = 20)
head(res.mca$ind$contrib)
fviz_mca_ind(res.mca, col.ind="contrib")+
scale_color_gradient2(low="white", mid="blue", 
                      high="red", midpoint=0.035)+theme_minimal()
plot.MCA(res.mca,choix=c("ind"),cex=0.8)
plot.MCA(res.mca,choix=c("ind"),invisible=c("ind"),cex=0.8)

```


## Representation of categories
We see that the pickup and dropoff coordinates and fare amount are best correlated to the first 2 dimentions. Rare categories can be found near the border such as Dispach.
```{r}
plot.MCA(res.mca,choix=c("ind"),invisible=c("ind"),axes=c(1,2))
lines(res.mca$quali.sup$coord[3:4,1],res.mca$quali.sup$coord[3:4,2],lwd=2,col="darkgreen") # Trencada dels nivells de f.fare_amount #??
lines(res.mca$quali.sup$coord[1:2,1],res.mca$quali.sup$coord[1:2,2],lwd=2,col="darkblue") # Trencada AnyTip
res.mca$var
plot.MCA(res.mca,choix=c("ind"),invisible=c("ind"),axes=c(3,4))
plot.MCA(res.mca,choix=c("var"))



```
We see that the the provider of the record,categories of the rate code are most contributive and the the type of the payment. Also it makes difference when it is night.
```{r}
# Contributions of rows to dimension 1
fviz_contrib(res.mca, choice = "var", axes = 1, top = 15)
# Contributions of rows to dimension 2
fviz_contrib(res.mca, choice = "var", axes = 2, top = 15)
# Total contribution to dimension 1 and 2
fviz_contrib(res.mca, choice = "var", axes = 1:2, top = 15)

head(round(res.mca$var$contrib,2), 10)

plot.MCA(res.mca,choix=c("ind"),invisible=c("ind"),axes=c(3,4))
plot.MCA(res.mca,choix=c("var"),axes=c(3,4))

# Use modern ggplot facilities
fviz_mca_var(res.mca, col.var="contrib",repel=TRUE)+
    scale_color_gradient2(low="green", mid="blue", 
    high="red", midpoint=0.75)+theme_bw()

fviz_mca_biplot(res.mca, invisible="ind",axes=1:2,repel=FALSE)+theme_bw()
```

V. Perform a MCA taking into account also supplementary variables (use all numeric variables) quantitative and/or categorical. How supplementary variables enhance the axis interpretation?

## MCA with all supplementary variables
```{r}
vars_con_pca <- names(df)[c(6:16,18,23:26,28)]
vec_out <- which(df$f.outlierPCA == "Outlier"); length(vec_out)
res.mca<-MCA(df[,c(vars_cat,vars_con_pca)], ind.sup = vec_out, quali.sup=c(4,14),quanti.sup=17:33,ncp=17)
```


Description of clusters
Parangons and class-specific individuals.
Comparison of clusters obtained after K-Means (based on PCA) and/or Hierarchical Clustering (based on PCA) focusing on f.total_amount target.
Comparison of clusters obtained after K-Means (based on PCA) and/or Hierarchical Clustering (based on PCA) focusing on AnyTip binary target.

# Synthesis through HCPC: Hierarchical Clustering

With the last MCA computation with 17 axes taken into account, we generate the clusters through hierarchical technique.

```{r}

res.hcpc<-HCPC(res.mca, nb.clust = 6,order=TRUE)
fviz_cluster(res.hcpc, geom = "point", main = "Factor map")
df$MCAhp<-7
df[row.names(res.hcpc$data.clust),"MCAhp"]<-res.hcpc$data.clust$clust
table(df$MCAhp)

```

## Description of clusters

```{r}
res.hcpc$desc.var

table (df$claHP, df$MCAhp)
claHPPCA<-factor(res.hcpcPCA$data.clust$clust,labels=paste("kHP-",1:8))
claHP<-factor(res.hcpc$data.clust$clust,levels=c(5,7,1,4,2,8,3,6),labels=c("kKM-5","kKM-7","kKM-1","kKM-4","kKM-2","kKM-8","kKM-3","kKM-6"))
tt<-table(claHPPCA,claHP)
tt
sum(diag(tt)/sum(tt))
```
