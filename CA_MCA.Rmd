---
title: "CA and MCA of NYCABS dataset"
author: "Katerina Dimitrova, Jose Romero, Sergi Munoz"
date: "March 18, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r,include=FALSE}
setwd("C://Users/Sergi/Desktop/Sergi/ADEI") #Change 
#setwd("D:/ADEI/ADEI.git/trunk") #Change

```

# Load Required Packages: to be increased over the course
```{r}
rm(list=ls())
requiredPackages <- c("effects","FactoMineR","car", "factoextra","RColorBrewer","ggplot2","missMDA","mvoutlier","dplyr","ggmap","ggthemes","knitr","MVA","corrplot")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

# Useful function and Data
#setwd("C://Users/Sergi/Desktop/Sergi/ADEI") #Change 
load("Taxi5000_raw_DataDefinitivev1.RData")
calcQ <- function(x) {
  s.x <- summary(x)
  iqr<-s.x[5]-s.x[2]
  list(souti=s.x[2]-3*iqr, mouti=s.x[2]-1.5*iqr, min=s.x[1], q1=s.x[2], q2=s.x[3],        q3=s.x[5], max=s.x[6], mouts=s.x[5]+1.5*iqr, souts=s.x[5]+3*iqr ) }
```

#Leveling 
For better understanding of the results we will name the levels of the factorial variables

```{r}
levels(df$f.fare_amount)
levels(df$f.passenger) <- c("onePassager","multiPassagers")
levels(df$f.pickup_longitude) <- c("p.Y1","p.Y2","p.Y3","p.Y4") #pickup->p., longtitude->Y
levels(df$f.pickup_latitude) <- c("p.X1","p.X2","p.X3","p.X4") #pickup->p., latitude->X
levels(df$f.distance) <- c("Dist1","Dist2", "Dist3", "Dist4")#distance 1-4, 1 shortest
levels(df$f.dropoff_longitude) <- c("d.Y1","d.Y2", "d.Y3", "d.Y4")
levels(df$f.dropoff_latitude) <- c("d.X1","d.X2", "d.X3", "d.X4")
levels(df$f.fare_amount) <- c("FAmount1","FAmount2", "FAmount3", "FAmount4")
levels(df$f.extra) <- c("smallExtra","highExtra")
levels(df$f.MTA_tax) <- c("smallMTA","highMTA")
levels(df$f.Improvement_surcharge) <- c("smallSurcharge","highSurcharge")
levels(df$f.tip_amount) <- c("smallTip","highTip")
levels(df$f.toll) <- c("smallToll","highToll")
levels(df$f.total) <- c("CheapestTrip","CheapTrip","MediumTrip","ExpensiveTrip")
levels(df$f.ttime) <- c("Time1","Time2", "Time3", "Time4")
levels(df$f.espeed) <- c("Speed1","Speed2", "Speed3","Speed4")
levels(df$f.outlierPCAd1) <- c("Normald1", "Outlierd1")
levels(df$f.outlierPCAd2) <- c("Normald2", "Outlierd2")
levels(df$f.outlierPCAd3) <- c("Normald3", "Outlierd3")
levels(df$f.outlierPCAd4) <- c("Normald4", "Outlierd4")
levels(df$f.outlierPCA) <- c("Normal", "Outlier")

```


# Correspondence Analysis: f.cost (discretization of Total_amount) vs f.hour and f.tt and period
In this section we will interprete two Correspondence Analysis executed on our discretizated target variable (f.total) with 2 different factors of our data: pick_up_period and f.espeed.

## Total_amount vs pick_up_period
We generate the contingency table for this two variables and execute the chisq test.

```{r}
tt<-table(df[,c("f.total","pick_up_period")])
tt
prop.table(tt,1)
prop.table(table(df$pick_up_period))

```
Before getting into the chisq test, taking a look to the contingency table we can actually say very little, because the categories of pick_up_period are not well balanced and so "afternoon" is always taking a higher number of individuals for each category.

For the previous reason, we look at their marginal tables to better extrapolate our first impressions.
The marginal table relative to f.total it is just a confirmation for what we already said (not very helpfull): we have an unbalanced distribution: most of the trips were made during the afternoon in every range of price contended.


```{r}
prop.table(tt,2)
prop.table(table(df$f.total))
```

Then, moving on to the second marginal table (now, relative to pick_up_period variable) things get more even.
we can appreciate that the cheapest trips take place, in a greater proportion, during the morning, as me can also say that during the night occur the most expensive trips. On the other hand, the medium price categories are more associated to the afternoon.   

```{r}
chisq.test(tt)
```

From the chi-square test we see that the p.value is less than 0.05 which meand that we can reject the Nul hypotesis thus the two factors are dependent. The df is 9 which means that the chi value of the threshold is 16,9 and we see that we have X-squared = 36,42 which is bigger than 16,9. => We can deffinetly reject the hypotesis. Factors are dependent and so we can affirm that the conclusions made above are statistically significant.


### CA plot interpretation
The plot visually represents all the information we could have interpreted from the tables:

- At night and morning the trips tend to be more expensive. 
- In the afternoon we find middle prices 
- Cheap trips stay at valley.


```{r}
res.ca<-CA(tt)
lines(res.ca$row$coord[,1],res.ca$row$coord[,2],lwd=2,col="blue")
summary(res.ca,dig=2)
fviz_ca_biplot(res.ca,repel=TRUE)+theme_bw()
```


### Eigenvalues and dominant axes analysis. How many axes we have to consider
The two first dimensions explain 99% of the variance, so there is no need of further exploration. (Actually, only the first dim has more than 94% of the variance). 
We can be confident that the patterns we see in the CA plot represent the patterns that we would see if we could peer into n-dimensional space.
```{r}
res.ca$eig
fviz_eig(res.ca)

```


### Individuals
For the next output we deduce that the more extreme individuals are actually the most contributive ones for the specific axe of their coordinates.

```{r}
res.ca$row$contrib[,1:2]
res.ca$row$coord[,1:2]

```

## Total_amount vs f.ttime
Now we will look at the contingency table for this two variables and execute the chisq test.

```{r}
tt<-table(df[,c("f.total","f.ttime")])
tt
prop.table(tt,1)
prop.table(table(df$f.ttime))
prop.table(tt,2)
prop.table(table(df$f.total))
chisq.test(tt)
```

We can appreciate a directionality between the increment of f.total and the f.ttime values. The diagonal of the contingency table has most of individuals contended and this is proved by the marginal tables too (no matter which one you look at). Lastly, they have a really good balanced distribution for each of their categories (almost equitative in each of them).

The chisq test numerically validates what we have already seen: these two variable are completetly dependent.

### CA plot interpretation
The plot shows a visual representation of the conclusion above: the longer the trips the more they cost.
```{r}
res.ca<-CA(tt)
lines(res.ca$row$coord[,1],res.ca$row$coord[,2],lwd=2,col="blue")
```

### Eigenvalues and dominant axes analysis. How many axes we have to consider
We need to consider the first 2 dimentions which together explains 90% of the data.

```{r}
res.ca$eig
fviz_eig(res.ca)
summary(res.ca)
res.ca$row$contrib[,1:2]
res.ca$row$coord[,1:2]
res.ca$row$cos2[,1:2]
sum(res.ca$eig[1:2,1])/sum(res.ca$eig[1:3,1])
sum(res.ca$eig[1:3,1])
res.ca$call$marge.col

fviz_eig(res.ca)
summary(res.ca,dig=2)
fviz_ca_biplot(res.ca,repel=TRUE)+theme_bw()

```



# Multiple Correspondence Analysis

In order to compute MCA we gather all the categorical variables that we want to use as an active ones in vars_cat vector.
We are not taking all distributed nor factors in it because we want to avoid using some extremely unbalanced variables such as Store_and_fwd_flag.

As a suplementary we will use the targets itselfs and the factor of the total_amount too.

```{r}
names(df)
vars_cat <- names(df)[c(1,19,20,22,27,29:35,39,41,42,43)]
#add f.totalamount as quali.sup
res.mca<-MCA(df[,c(vars_cat,"Total_amount")],quali.sup=c(4,14),quanti.sup=17)
```

## Axes analysis
Below are shown the histograms of Eigen values and explained variances -in this order- as the numerical table for each dimension.
In order to get the number of dimensions which we will take into account from now on, we keep only the dimensions associated to eigenvalues greater than 1/(nbvar), which is until the 17th dimension and we got almost 80% of the variance explained. 

```{r}
fviz_eig(res.mca)
fviz_screeplot(res.mca, addlabels = TRUE, ylim = c(0, 45))
get_eig(res.mca)
length <-length(which(res.mca$eig[,1]>=(1/length(df[,c(vars_cat)]))));length 
res.mca$eig[1:length,1]
summary(res.mca, dig=2,nbelements=50, ncp=4)
```



## Individuals
We have 4866 observation so each individual should have 100/4866 ~ 0.02 contribution.So the expected avaradge contribution is 0.02*Dim1 + 0.02*Dim2 = 0.02*0.1+0.02*0.78 = 0.035.So as we see in the two plots there are some too contributive individuals.

Too contributive groups would be:
- Individuals with longest travel time, high total price, high fare amount and longest distance
- Individulas with shortest travel time, lowest Fare Amount and lowest total amount
- Individuals with a dispach trip type and the biggest pickup and dropoff longtitude
- Individuals with smallest pickup and droppoff longitude and latitude.
```{r}

fviz_contrib(res.mca, choice = "ind", axes = 1:2, top = 20)
head(res.mca$ind$contrib)
fviz_mca_ind(res.mca, col.ind="contrib")+
scale_color_gradient2(low="white", mid="blue", 
                      high="red", midpoint=0.035)+theme_minimal()
plot.MCA(res.mca,choix=c("ind"),cex=0.8)
plot.MCA(res.mca,choix=c("ind"),invisible=c("ind"),cex=0.8)

```


## Representation of categories
We see that the pickup and dropoff coordinates and fare amount are best correlated to the first 2 dimentions. Rare categories can be found near the border such as Dispach.
```{r}
plot.MCA(res.mca,choix=c("ind"),invisible=c("ind"),axes=c(1,2))
lines(res.mca$quali.sup$coord[3:4,1],res.mca$quali.sup$coord[3:4,2],lwd=2,col="darkgreen") # Trencada dels nivells de f.fare_amount #??
lines(res.mca$quali.sup$coord[1:2,1],res.mca$quali.sup$coord[1:2,2],lwd=2,col="darkblue") # Trencada AnyTip
res.mca$var
plot.MCA(res.mca,choix=c("ind"),invisible=c("ind"),axes=c(3,4))
plot.MCA(res.mca,choix=c("var"))



```
We see that the the provider of the record,categories of the rate code are most contributive and the the type of the payment. Also it makes difference when it is night.
```{r}
# Contributions of rows to dimension 1
fviz_contrib(res.mca, choice = "var", axes = 1, top = 15)
# Contributions of rows to dimension 2
fviz_contrib(res.mca, choice = "var", axes = 2, top = 15)
# Total contribution to dimension 1 and 2
fviz_contrib(res.mca, choice = "var", axes = 1:2, top = 15)

head(round(res.mca$var$contrib,2), 10)

plot.MCA(res.mca,choix=c("ind"),invisible=c("ind"),axes=c(3,4))
plot.MCA(res.mca,choix=c("var"),axes=c(3,4))

# Use modern ggplot facilities
fviz_mca_var(res.mca, col.var="contrib",repel=TRUE)+
    scale_color_gradient2(low="green", mid="blue", 
    high="red", midpoint=0.75)+theme_bw()

fviz_mca_biplot(res.mca, invisible="ind",axes=1:2,repel=FALSE)+theme_bw()
```



## MCA with all supplementary variables
```{r}
vars_con_pca <- names(df)[c(6:16,18,23:26,28)]
vec_out <- which(df$f.outlierPCA == "Outlier"); length(vec_out)
res.mca<-MCA(df[,c(vars_cat,vars_con_pca)], ind.sup = vec_out, quali.sup=c(4,14),quanti.sup=17:33,ncp=17)
```


Parangons and class-specific individuals.

# Synthesis through HCPC: Hierarchical Clustering

With the last MCA computation with 17 axes taken into account, we generate the clusters through hierarchical technique.

```{r}

res.hcpc<-HCPC(res.mca, nb.clust = 6,order=TRUE)
fviz_cluster(res.hcpc, geom = "point", main = "Factor map")
df$MCAhp<-7
df[row.names(res.hcpc$data.clust),"MCAhp"]<-res.hcpc$data.clust$clust
table(df$MCAhp)

```

## Description of clusters

```{r}
res.hcpc$desc.var
```

### Cluster 1
#### Category
86% of its individuals have the CheapestTrip category for f.total. Dist1, FAmount1 and Time1 for their respective variables (f.distance,  f.fare_amount and f.ttime) are also predominant (more than 85% in Mod/Cla for each one). This means that Cluster 1 is defined by the cheapest and shortest trips with a small tips. 
#### Quanti
As a prove of the conclusions made before, we can see how the most remarkable quantitatives variables are trip_length, Fare_amount, Total_amount and travel_time. The mean of all of this variables inside the cluster is clearly above the overall mean in the dataset.

### Cluster 2
#### Category
We can see that here we still have a predominance of cheap trips (with a 71% of individuals of cluster 2 have cheaptrip) but now f.distance, f.fare_amount and f.ttime get their second level (category) of values. So we got cheap trips with a bigger distances than in cluster 1 here.
#### Quanti
The same as the case before. The numerical variables agreed with the conclusions made. The most significance variables are still trip_length, Fare_amount, Total_amount and travel_time and their mean is a bit higher than the cluster1 but still above the overall mean. 

### Cluster 3
#### Category
In cluster 3 seems to be still splitting by its cost and lentgh of the journey, now with middle trips which contains medium costs (77% of the rows) and the 3rd level of f.fare_amount, f.distance and time, which also means longer trips than before. 
#### Quanti
Travel time and trip_length in this cluster are in the mean values, which is logic for what we just said, but it is curious how the variables with biggest v.test values are actually longitudes and latitudes.  

### Cluster 4
#### Category
Clearly defined by one parameter: the type of the trip "Dispatch". 100% of its individuals are of this type and 100% of this category is included in this cluster. 
#### Quanti
MTA_tax is the most remarkable variables here and it doesn't say too much except of the cluster except we only have rows without taxes nor extra's.

### Cluster 5
#### Category
It has been build from the longitutds and latitudes of the first level/category of the pick_up and dropoff variables.
#### Quanti
As we already pointed out, mostly longitudes and latitudes involved here.

###Cluster 6
#### Category
Here we find the most expensive trips with all the elements that it follows from it: large trips (Dist4) that take a lot of time (Time4) with a big Fare amount (FAmount4). All of this classes have more than 85% of representation inside this cluster.
#### Quanti
Fare_amount, trip_length, travel_time and Total_amount clearly over the overall mean and with a lot of significance here.

## Individuals
Again, this command can help us now to confirm the conclusions made until now.

```{r}
res.hcpc$desc.ind
```

### Cluster 1
For a parangon of C1 we expect some row with a cheapTrip and short distance. We can check Total_amount (8.3) is below the mean (11.0) as the rest of significant quantitatives variables explained for Cluster1.
On the contrary, for the distinguished, we have a Total_amount over the mean (20.34).

```{r}
#parangon C1
df["419422",]
#distinguished C1
df["572868",]
```


### Cluster 2
Cheap trips (total_amount below the mean) with bigger distances than cluster 1 for parangons as we predicted.

```{r}
#parangon 
df["746656",]
#distinguished 
df["532659",]
```


### Cluster 3
Parangon with medium costs -> total_amount in the mean.
Distinguished with high espeed and low travel_time

```{r}
#parangon 
df["473230",]
#distinguished 
df["274842",]
```


### Cluster 4


```{r}
#parangon 
df["473235",]
#distinguished 
df["1137082",]
```


### Cluster 5


```{r}
#parangon C1
df["272451",]
#distinguished C1
df["675043",]
```


### Cluster 6


```{r}
#parangon C1
df["678042",]
#distinguished C1
df["285458",]
```


## Comparison with PCA clustering
As it fails everytime we re-execute this commands, we commented it in order to show the proper results.

```{r}
#tt<-table(df$claHP,df$MCAhp)
#df$MCAhp<-factor(df$MCAhp,levels=c(1,3,5,2,4,6,7),labels=c("mcaC-1","mcaC-3","mcaC-5","mcaC-2","mcaC-4","mcaC-6","mcaC-7"))
#tt<-table(df$claHP,df$MCAhp)
tt
sum(diag(tt)/sum(tt))
```

We can see, thou, that only with the table of contingencies is enough to appreciate how different are the clusters generated by both techniques.
The diagonal summatory it's about 0.5 which means only a 50% of matching in the cluster structure.

To conclude, for our target total_amount, this clustering with MCA is taking a better approach to split by its categories (low, medium, and high prices) than the clusterings resulting from numerical PCA method.
