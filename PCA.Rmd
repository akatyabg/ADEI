---
title: "PCA analysis of NYCABS datase"
author: "Katerina Dimitrova, Jose Romero, Sergi Munoz"
date: "March 18, 2018"
output: pdf_document
---

```{r,include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)

```

```{r,include=FALSE}
#setwd("C://Users/Sergi/Desktop/Sergi/ADEI") #Change 
setwd("D:/ADEI/ADEI.git/trunk") #Change

```

#Previous work

## Load requiered packages

```{r,include=FALSE}
rm(list=ls())
requiredPackages <- c("effects","FactoMineR","car", "factoextra","RColorBrewer","ggplot2","missMDA","mvoutlier","dplyr","ggmap","ggthemes","knitr","MVA")
missingPackages <- requiredPackages[!(requiredPackages %in% installed.packages()[,"Package"])]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

# Useful function
calcQ <- function(x) {
  s.x <- summary(x)
  iqr<-s.x[5]-s.x[2]
  list(souti=s.x[2]-3*iqr, mouti=s.x[2]-1.5*iqr, min=s.x[1], q1=s.x[2], q2=s.x[3],        q3=s.x[5], max=s.x[6], mouts=s.x[5]+1.5*iqr, souts=s.x[5]+3*iqr ) }

```


#PCA analysis
1. The Kaiser rule is to drop all components with eigenvalues under 1.0 
   According to the Elbow rule when the drop ceases and the curve makes an elbow toward less steep declinewe should drop all further components after the one starting the elbow.
   
##I. I. Eigenvalues and  axes 
For the PCA analysis we take all numerical variables as activ, where TotalAmount nd Anytip are supementary.
```{r}
load("Taxi5000_raw_DataClean.RData")
library(FactoMineR)
names (df)
vars_con_pca<-c(6,7,8,9,10,11,12,13,14,15,16,17,18,22,23,24,25,26) 

#From te plot we see that the variables "Trip_distance", "Trip_length", "Travel_time" and "Fare_amount" are stong correlated to "Total_amount", where as the pickup and dropoff latitude and longtitude are correlated with each other but dont have any relation to "Total_amount". The rest of the variables such as the "Passanger_count" and the different taxes and fees are also independent.
res.pca<-PCA(df[,vars_con_pca], quanti.sup = 13, quali.sup = 14, ncp = 6 ) # TotalAmount and AnyTip

barplot(res.pca$eig[,1], main="Eigenvalues", names.arg = paste("dim", 1:nrow(res.pca$eig)))
# With the PCA transformation the PC1 covers 29% of the variance, PC2 - 15,5%, PCA3 - 11%, PCA4 - 9,3% and the rest around 5-6% or less.
plot(res.pca$eig[,1], type = "l") # line chart
length <-length(which(res.pca$eig[,1]>=1));length 
kaiser <- res.pca$eig[1:length,1] #keep only EV >=1 ->first 7
#If we use the kaiser rule we have to keep all EV greater than 1, which results in saving the first 6 dimetions and 84,6% of the variance. 
#facto extra
fviz_eig(res.pca, addlabels = TRUE)
fviz_eig(res.pca, choice = "eigenvalue",addlabels = TRUE)
#According to the elbow rule we have to take the first 6 dimentions as the slope of the graphic shows. We are going to follow this rule. 78,6 % of the variance is saved
elbow <- kaiser

```

##II.  Individuals point of view
## Look at variables that are too contributive
```{r}
summary(res.pca, dig = 2, nbelements = 17, nbind=3, ncp=4)
#The summary confirms the correlations between the variables that we already interpreted from the plots earlier.
#The plot show us that individuals that had to pay more tend to leave a tip.
plot.PCA(res.pca, choix=c("ind"),cex=0.8,col.ind="grey80",select="contrib15",axes=c(1,2))

#DIMENSION1
#Since the multivariant detection didnt manage to find outliers well enogh we are going to obtain them from the PCs. We will obtain outliers from the first 4 dimentions. 

#characteristic of extreme otliers in dim1
summary(res.pca$ind$coord[,1])
iqrvar<-IQR(res.pca$ind$coord[,1])
quantil3<-quantile(res.pca$ind$coord[,1], .75);quantil3 #get 3rd quartile
outliers<-which(res.pca$ind$coord[,1]>(iqrvar*3)+quantil3);length(outliers)

df$f.outlierPCAd1<-0
df[outliers,"f.outlierPCAd1"]<-1
df$f.outlierPCAd1<-factor(df$f.outlierPCAd1,labels=c("NoOutDim1", "YesOutDim1"))
summary(df$f.outlierPCAd1)
names(df)
#catdes(,names(df)[c(22)])

#DIMENSION2
#characteristic of extreme otliers in dim1
summary(res.pca$ind$coord[,2])
iqrvar<-IQR(res.pca$ind$coord[,2])
quantil3<-quantile(res.pca$ind$coord[,2], .75);quantil3 #get 3rd quartile
outliers2<-which(res.pca$ind$coord[,2]>(iqrvar*3)+quantil3);length(outliers2)


df$f.outlierPCAd2<-0
df[outliers2,"f.outlierPCAd2"]<-1
df$f.outlierPCAd2<-factor(df$f.outlierPCAd2,labels=c("NoOutDim2", "YesOutDim2"))
summary(df$f.outlierPCAd2)
names(df)

#DIMENSION3
#characteristic of extreme otliers in dim1
summary(res.pca$ind$coord[,3])
iqrvar<-IQR(res.pca$ind$coord[,3])
quantil3<-quantile(res.pca$ind$coord[,3], .75);quantil3 #get 3rd quartile
outliers3<-which(res.pca$ind$coord[,3]>(iqrvar*3)+quantil3);length(outliers3)


df$f.outlierPCAd3<-0
df$f.outlierPCAd3<-factor(df$f.outlierPCAd3,labels=c("NoOutDim3"))
summary(df$f.outlierPCAd3)
names(df)

#DIMENSION4
#characteristic of extreme otliers in dim1
summary(res.pca$ind$coord[,4])
iqrvar<-IQR(res.pca$ind$coord[,4])
quantil3<-quantile(res.pca$ind$coord[,4], .75);quantil3 #get 3rd quartile
outliers4<-which(res.pca$ind$coord[,4]>(iqrvar*3)+quantil3);length(outliers4)


df$f.outlierPCAd4<-0
df$f.outlierPCAd4<-factor(df$f.outlierPCAd4,labels=c("NoOutDim4"))
summary(df$f.outlierPCAd4)
names(df)

#Finally we obtained 62 extreme outliers. 
llvout<- c(outliers, outliers2);length(llvout)

catdes(df, 42)

```


##III Interpret axis
```{r}
# Interential criteria

dimdesc (res.pca, axes=1:4)
#The first Dimention is best described by the quantative variables Total_amount, trip_distance and Fare_amount. The second one - by the coordinates of the beginning and end of the trip, The third one - by the MTA_tax and improvement_surcharge and the forth one - by the longtitute of the pickup and dropoff point.
plot(res.pca,choix="var", cex = 0.75)
plot(res.pca,choix="var", cex = 0.75, axes = (3:4))# 3rd and 4th PCA
#modern factoextra

fviz_pca_var(res.pca,col.var="cos2", repel=TRUE)+scale_color_gradient2(low="green", mid="blue", high="red",midpoint=0.5)+theme_bw()


```

##IV PCA execution with supplementary individuals
```{r}
vec_out <- llvout
vars_con_pca <- names(df)[c(6:16,18,23:26)]
# We do a PCA analysis using the factorial variables Fare amount, total and the pickup perio in order to interpret the results even better. We use the discovered outliers as suplementary individuals.

res.pca<-PCA(df[,c(vars_con_pca, "f.fare_amount", "f.total", "pick_up_period")], ncp=6, quanti.sup=which(vars_con_pca=="Total_amount"), ind.sup = vec_out, quali.sup = 17:19, graph= FALSE)

plot(res.pca,choix="var", cex = 0.75)
plot(res.pca,choix="var", cex = 0.75, axes = (3:4))# 3rd and 4th PCA
fviz_pca_var(res.pca,col.var="cos2", repel=TRUE)+scale_color_gradient2(low="green", mid="blue", high="red",midpoint=0.5)+theme_bw()

#We can see that trips in the afternoon tend to be longer and thus also more expensive than the ones during night and in the morning.
plot.PCA(res.pca, choix=c("ind"),cex=0.8,col.ind="grey80",select="contrib15",axes=c(1,2))


```


#Hierarchical clustering

Generem 8 clusters amb el metode Hierarchichal a partir de les projeccions obtingudes amb el PCA.

```{r}
library(FactoMineR)
library (ggplot2)
library(ggdendro)

res.hcpc <-HCPC(res.pca, nb.clust = 6, order=TRUE)
table (res.hcpc$data.clust$clust)
```


```{r}

#Block A descripció per variables
res.hcpc$desc.var
```

```{r}

#Block B descripció per eixos
#She doesn't recommend that (not very usefull by her opinion)
res.hcpc$desc.axes
```

```{r}
#Block C individus
#parangons. per cadascun dels clusters tenim els seus parangons i els seus més espeicifis (dist) -> que es diferencien més dels altres clusters
res.hcpc$desc.ind
```

```{r}

#Donar-li una classe (the last one) a tots els outliers multidimensionals (sup.)
df$claHP<-7
df[row.names(res.hcpc$data.clust),"claHP"]<-res.hcpc$data.clust$clust
table(df$claHP)

#No ens hem de preocupar de la clase outliers, només caracteritizar els clusters del metode per defecte que genera la classificació jerarquica. 

```

#K-Means Classification

```{r}

ppcc<-res.pca$ind$coord[,1:6]
dim(ppcc)
kc<-kmeans(ppcc,6,iter.max = 30, trace=T)
table(kc$cluster)
```

```{r}

df$claKM<-7
df[names(kc$cluster),"claKM"]<-kc$cluster
kc$betweenss/kc$totss
table(df$claKM)
```

```{r}
#caracteristació claKM
catdes(df, 44)
#veure si s'han posat d'acord o no
table(df$claHP,df$claKM)
```

```{r}

df$claHP<-factor(df$claHP,labels=paste("kHP-",1:7))
df$claKM<-factor(df$claKM,levels=c(2,3,1,5,4,6,7),labels=c("kKM-2","kKM-3","kKM-1","kKM-5","kKM-4","kKM-6","kKM-7"))
tt<-table(df$claHP,df$claKM)
tt
sum(diag(tt)/sum(tt))

```


```{r, include=false}
kMeansCluster <- kmeans(res.pca$ind$coord, 4, nstart = 20)
kMeansCluster <- kmeans(res.pca$ind$coord[,1:6],center= 3)


kMeansCluster$clusterF <-as.factor(kMeansCluster$cluster)
elbowDF<-data.frame(res.pca$ind$coord)
ggplot(elbowDF, aes(elbowDF$Dim.1,elbowDF$Dim.2 , color = kMeansCluster$clusterF)) + geom_point()
```


